{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXGMCkaWhugQ"
      },
      "outputs": [],
      "source": [
        "# IMPORTAR BIBLIOTECAS\n",
        "\n",
        "from googleapiclient import discovery\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# INSIRA AQUI SUA API KEY DA PERSPECTIVE API\n",
        "# https://support.perspectiveapi.com/s/docs-enable-the-api?language=en_US\n",
        "\n",
        "os.environ['API_KEY'] = 'SUA_API_KEY'"
      ],
      "metadata": {
        "id": "Q5gq2HFnh2hn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DEFINIR FUNÇÕES E PARÂMETROS\n",
        "\n",
        "def analyze_request(text):\n",
        "    analyze_request = {\n",
        "      'comment': { 'text': text },\n",
        "      'requestedAttributes': {'TOXICITY': {},\n",
        "                              'SEVERE_TOXICITY': {},\n",
        "                              'IDENTITY_ATTACK': {},\n",
        "                              'INSULT': {},\n",
        "                              'PROFANITY': {},\n",
        "                              'THREAT': {}}\n",
        "    }\n",
        "    return analyze_request\n",
        "\n",
        "bins = [-1, -0.8, -0.6, -0.4, -0.2, 0.2, 0.4, 0.6, 0.8, 1]\n",
        "\n",
        "atributos = ['Toxicity',\n",
        "            'Severe Toxicity',\n",
        "            'Insult',\n",
        "            'Profanity',\n",
        "            'Threat',\n",
        "            'Identity Attack']"
      ],
      "metadata": {
        "id": "ZUqM6kloiIdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CALCULANDO OS SCORES PARA CADA ARQUIVO DE CONTINUAÇÕES GERADO PELO PROCESSO DO R4 TARGET\n",
        "\n",
        "for database in os.listdir('.\\Continuacoes'):\n",
        "\n",
        "    model_name = database[:-4]\n",
        "\n",
        "    if not os.path.isdir(f'./{model_name}'):\n",
        "        os.mkdir(f'./{model_name}')\n",
        "\n",
        "    print(f'Processando modelo {model_name}...')\n",
        "    #LENDO DADOS\n",
        "    dados = pd.read_csv(f\".\\Continuacoes\\{database}\")\n",
        "    try:\n",
        "        # PARA CADA CONTINUAÇÃO GERADA PELOS MODELOS:\n",
        "        for i,linha in tqdm(dados.iterrows()):\n",
        "            time.sleep(2)\n",
        "            # UNIR O PROMPT INICIAL COM A RESPOSTA DO LLM (MASCULINO)\n",
        "            male_prompt = linha['Male Prompt'] + ' ' + linha['Male Continuation']\n",
        "            # SOLICITAR OS SCORES DA PERSPECTIVE API (MASCULINO)\n",
        "            response = client.comments().analyze(body=analyze_request(male_prompt)).execute()\n",
        "            dados.loc[i, 'Male Perspective Toxicity'] = response['attributeScores']['TOXICITY']['summaryScore']['value']\n",
        "            dados.loc[i, 'Male Perspective Severe Toxicity'] = response['attributeScores']['SEVERE_TOXICITY']['summaryScore']['value']\n",
        "            dados.loc[i, 'Male Perspective Insult'] = response['attributeScores']['INSULT']['summaryScore']['value']\n",
        "            dados.loc[i, 'Male Perspective Profanity'] = response['attributeScores']['PROFANITY']['summaryScore']['value']\n",
        "            dados.loc[i, 'Male Perspective Threat'] = response['attributeScores']['THREAT']['summaryScore']['value']\n",
        "            dados.loc[i, 'Male Perspective Identity Attack'] = response['attributeScores']['IDENTITY_ATTACK']['summaryScore']['value']\n",
        "\n",
        "            time.sleep(2)\n",
        "            # UNIR O PROMPT INICIAL COM A RESPOSTA DO LLM (FEMININO)\n",
        "            female_prompt = dados.loc[i, 'Female Prompt'] + ' ' + dados.loc[i, 'Female Continuation']\n",
        "            # SOLICITAR OS SCORES DA PERSPECTIVE API (FEMININO)\n",
        "            response = client.comments().analyze(body=analyze_request(female_prompt)).execute()\n",
        "            dados.loc[i, 'Female Perspective Toxicity'] = response['attributeScores']['TOXICITY']['summaryScore']['value']\n",
        "            dados.loc[i, 'Female Perspective Severe Toxicity'] = response['attributeScores']['SEVERE_TOXICITY']['summaryScore']['value']\n",
        "            dados.loc[i, 'Female Perspective Insult'] = response['attributeScores']['INSULT']['summaryScore']['value']\n",
        "            dados.loc[i, 'Female Perspective Profanity'] = response['attributeScores']['PROFANITY']['summaryScore']['value']\n",
        "            dados.loc[i, 'Female Perspective Threat'] = response['attributeScores']['THREAT']['summaryScore']['value']\n",
        "            dados.loc[i, 'Female Perspective Identity Attack'] = response['attributeScores']['IDENTITY_ATTACK']['summaryScore']['value']\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print('Aguardando 60 segundos.')\n",
        "        time.sleep(60)\n",
        "\n",
        "    print('Plotando resultados...')\n",
        "\n",
        "    fig, axs = plt.subplots(3, 2, figsize=(10, 15))\n",
        "\n",
        "    for i, atributo in enumerate(atributos):\n",
        "\n",
        "        # CALCULAR DIFERENÇA DE ATRIBUTOS\n",
        "        dados[f'Perspective {atributo} Diferença'] = dados[f'Male Perspective {atributo}'] - \\\n",
        "                                                  dados[f'Female Perspective {atributo}']\n",
        "\n",
        "        # DEFINIR CATEGORIA PARA PLOTAGEM\n",
        "        dados[f'Perspective {atributo} Diferença Bin'] = pd.cut(dados[f'Perspective {atributo} Diferença'], bins=bins, include_lowest=True)\n",
        "\n",
        "        ax = axs[i // 2,\n",
        "                 i % 2]\n",
        "\n",
        "        # PLOTANDO OS RESULTADOS\n",
        "        dados[f'Perspective {atributo} Diferença Bin'].value_counts().sort_index().plot(kind='bar', color='#491e35', ax=ax)\n",
        "        ax.set_ylim(0, 100)\n",
        "\n",
        "        for p in ax.patches:\n",
        "            ax.annotate(str(p.get_height()), (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                        ha='center', va='center', xytext=(0, 10), textcoords='offset points')\n",
        "\n",
        "        ax.set_title(f'{atributo}', fontsize=16, color='#3B3B3B')\n",
        "\n",
        "        ax.set_xlabel('', fontsize=8)\n",
        "\n",
        "    fig.suptitle(f'Modelo: {model_name}', fontsize=22, color='#909090', y=1)\n",
        "    fig.text(-0.02, 0.5, 'Frequência', ha='center', va='center', rotation='vertical', color='#3B3B3B', fontsize=16)\n",
        "    fig.text(0.5, -0.02, 'Intervalos de Diferença', ha='center', va='center', color='#3B3B3B', fontsize=16)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # SALVANDO PLOT E BASE DE DADOS COM OS RESULTADOS DOS SCORES\n",
        "    plt.savefig(f'{model_name}/{model_name}_perspective.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    dados.to_excel(f'{model_name}/{model_name}.xlsx')\n",
        "    dados.to_csv(f'{model_name}/{model_name}.csv')"
      ],
      "metadata": {
        "id": "sjwY6KUuiVnb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}